{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (6.0, 4.0) # this controls figure size in the notebook\n",
    "\n",
    "SEED = 42 # 42 is the seed used by us for the experiments\n",
    "PATCH_SIZE = 8 # Pixel side size of the patches\n",
    "EXAMPLE_SIZE = 256 # Pixel side size of the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"zaraks/pascal-voc-2007\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image # we use PIL due to problems with cv2 for opening images due to unicode present in path\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "def generate_patch(path, height, width, verbose=False, seed=None):\n",
    "    \"\"\"\n",
    "    Generate a height x width greyscale patch from a random\n",
    "    image sampled from the ones in the given path\n",
    "\n",
    "    Args:\n",
    "        path (str): location of image (.png or .jpg) dataset\n",
    "        height (int): height of patch, must be positive\n",
    "        width (int): width of patch, must be positive\n",
    "        verbose (bool): whether to print how many images can be used to generate patches\n",
    "        seed (int): the seed to be used for the random number generator\n",
    "\n",
    "    Returns:\n",
    "        Image: generated patch, or None if height or width are invalid\n",
    "    \"\"\"\n",
    "    \n",
    "    if (height<1 or width<1):\n",
    "        print(\"invalid height or width, they must be positive\")\n",
    "        return None\n",
    "    \n",
    "    # Sets seed\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # List all image files in the directory, sorted to make it deterministic\n",
    "    image_files = sorted([os.path.join(path, f) for f in os.listdir(path) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "\n",
    "    # Filter images based on size\n",
    "    valid_images = []\n",
    "    for image_file in image_files:\n",
    "        with Image.open(image_file) as img:\n",
    "            if img.size[0] >= width and img.size[1] >= height:\n",
    "                valid_images.append(image_file)\n",
    "\n",
    "    if len(valid_images)<1 :\n",
    "        print(f\"No valid images found\")\n",
    "        return None\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Found {len(valid_images)} valid images\")\n",
    "\n",
    "    # Select a random image from the valid images\n",
    "    random_image = random.choice(valid_images)\n",
    " \n",
    "     # Open the selected image\n",
    "    with Image.open(random_image) as img:\n",
    "        # Convert image to greyscale\n",
    "        img = img.convert(\"L\")\n",
    "        # Generate a random patch\n",
    "        x = random.randint(0, img.size[0] - width)\n",
    "        y = random.randint(0, img.size[1] - height)\n",
    "        patch = img.crop((x, y, x + width, y + height))\n",
    "    \n",
    "    \n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a patch and plot it to check the correctness of the function\n",
    "\n",
    "patch = generate_patch(path + \"/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages\", \n",
    "                       EXAMPLE_SIZE, EXAMPLE_SIZE, seed=SEED)\n",
    "\n",
    "plt.imshow(patch,\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patches(path, height, width, num_patches, verbose=False, seed=None):\n",
    "    \"\"\"\n",
    "    Generate n height x width greyscale patches from random\n",
    "    images sampled from the ones in the given path\n",
    "\n",
    "    Args:\n",
    "        path (str): location of image (.png or .jpg) dataset\n",
    "        height (int): height of patch, must be positive\n",
    "        width (int): width of patch, must be positive\n",
    "        num_patches (int): number of patches you want to generate\n",
    "        verbose (bool): whether to print how many images can be used to generate patches\n",
    "        seed (int): the seed to be used for the random number generator\n",
    "\n",
    "    Returns:\n",
    "        NDarray[NDarray]: numpy array of generated patches in the format needed by \n",
    "                        MiniBatchDictionaryLearning, or None if height or width are invalid\n",
    "    \"\"\"\n",
    "    \n",
    "    if (height<1 or width<1):\n",
    "        print(\"invalid height or width, they must be positive\")\n",
    "        return None\n",
    "    \n",
    "    # Sets seed\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # List all image files in the directory, sorted to make it deterministic\n",
    "    image_files = sorted([os.path.join(path, f) for f in os.listdir(path) if f.endswith('.jpg') \n",
    "                          or f.endswith('.png')])\n",
    "\n",
    "    # Filter images based on size\n",
    "    valid_images = []\n",
    "    for image_file in image_files:\n",
    "        with Image.open(image_file) as img:\n",
    "            if img.size[0] >= width and img.size[1] >= height:\n",
    "                valid_images.append(image_file)\n",
    "\n",
    "    if len(valid_images)<1 :\n",
    "        print(f\"No valid images found\")\n",
    "        return None\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Found {len(valid_images)} valid images\")\n",
    "\n",
    "    \n",
    "    # Initialize an array to store patches\n",
    "    patches = numpy.empty((num_patches,height*width), dtype=numpy.uint8)\n",
    "    for i in range(num_patches):\n",
    "        # Select a random image from the valid images\n",
    "        random_image = random.choice(valid_images)\n",
    "        with Image.open(random_image) as img:\n",
    "            # Convert image to greyscale\n",
    "            img = img.convert(\"L\")\n",
    "            # Generate a random patch\n",
    "            x = random.randint(0, img.size[0] - width)\n",
    "            y = random.randint(0, img.size[1] - height)\n",
    "            patch = img.crop((x, y, x + width, y + height))\n",
    "            patches[i]=numpy.array(patch).flatten()\n",
    "\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# Function to generate multiple patches within a worker thread\n",
    "def extract_patches(worker_id, images_subset, num_patches, height, width, seed):\n",
    "    try:\n",
    "        # Unique seed for each worker\n",
    "        random.seed(seed + worker_id)  \n",
    "        numpy.random.seed(seed + worker_id)\n",
    "\n",
    "        # Initialize an array to store patches\n",
    "        patches = numpy.empty((num_patches,height*width), dtype=numpy.uint8)\n",
    "        \n",
    "        for i in range(num_patches):\n",
    "            # Select a random image from the valid images\n",
    "            random_image = random.choice(images_subset)\n",
    "            with Image.open(random_image) as img:\n",
    "                # Convert to grayscale\n",
    "                img = img.convert(\"L\")  \n",
    "                # Generate a random patch\n",
    "                x = random.randint(0, img.size[0] - width)\n",
    "                y = random.randint(0, img.size[1] - height)\n",
    "                patch = img.crop((x, y, x + width, y + height))\n",
    "                patches[i]=numpy.array(patch).flatten()\n",
    "\n",
    "        return patches\n",
    "\n",
    "    except Exception as e:\n",
    "        # Return an empty array instead of crashing\n",
    "        print(f\"Worker {worker_id} failed: {e}\")\n",
    "        return numpy.empty((0, height * width), dtype=numpy.uint8)  \n",
    "\n",
    "def generate_patches_concurrent(path, height, width, n, verbose=False, seed=None, num_workers=12):\n",
    "    \"\"\"\n",
    "    Generate n height x width greyscale patches from random\n",
    "    images sampled from the ones in the given path in a concurrent manner\n",
    "\n",
    "    Args:\n",
    "        path (str): location of image (.png or .jpg) dataset\n",
    "        height (int): height of patch, must be positive\n",
    "        width (int): width of patch, must be positive\n",
    "        n (int): number of patches you want to generate\n",
    "        verbose (bool): whether to print how many images can be used to generate patches\n",
    "        seed (int): the seed to be used for the random number generator\n",
    "        num_workers (int): number of threads you want to use\n",
    "\n",
    "    Returns:\n",
    "        NDarray[NDarray]: numpy array of generated patches in the format needed by \n",
    "                        MiniBatchDictionaryLearning, or None if height or width are invalid\n",
    "    \"\"\"\n",
    "\n",
    "    if height < 1 or width < 1:\n",
    "        print(\"Invalid height or width, they must be positive\")\n",
    "        return None\n",
    "\n",
    "    # Sets seed\n",
    "    random.seed(seed)\n",
    "\n",
    "    # List all image files in the directory, sorted to make it deterministic\n",
    "    image_files = sorted([os.path.join(path, f) for f in os.listdir(path) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "\n",
    "    # Filter images based on size\n",
    "    valid_images = [img for img in image_files if Image.open(img).size[0] >= width and Image.open(img).size[1] >= height]\n",
    "\n",
    "    if len(valid_images) < 1:\n",
    "        print(f\"No valid images found\")\n",
    "        return None\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Found {len(valid_images)} valid images\")\n",
    "\n",
    "    # Divide images fairly among workers\n",
    "    image_chunks = numpy.array_split(valid_images, num_workers)\n",
    "    num_patches_per_worker = n // num_workers\n",
    "\n",
    "    # Initialize empty array to store patches\n",
    "    patches = numpy.empty((n, height * width), dtype=numpy.uint8)\n",
    "\n",
    "    # Run parallel execution with ThreadPoolExecutor\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(extract_patches, i, image_chunks[i], num_patches_per_worker, \n",
    "                            height, width, seed): i\n",
    "            for i in range(num_workers)\n",
    "        }\n",
    "\n",
    "        # Collect results and merge into final patches array\n",
    "        start_idx = 0\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            worker_patches = future.result()\n",
    "\n",
    "            # Ensure worker returned valid patches before assigning\n",
    "            if worker_patches.shape[0] > 0:\n",
    "                patches[start_idx:start_idx + worker_patches.shape[0]] = worker_patches\n",
    "                start_idx += worker_patches.shape[0]\n",
    "\n",
    "    return patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "\n",
    "dataset=generate_patches_concurrent(path + \"/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages\", \n",
    "                         PATCH_SIZE, PATCH_SIZE, 10**4, False, seed=SEED)\n",
    "\n",
    "# Check the shape of the dataset\n",
    "print(dataset.shape)\n",
    "\n",
    "# train the dictionary\n",
    "model = MiniBatchDictionaryLearning(alpha=1, max_iter=1000, n_jobs=-1, fit_algorithm='lars', \n",
    "                                   batch_size=256, random_state=SEED)\n",
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us make a noisy image \n",
    "import cv2\n",
    "def add_gaussian_noise(image, mean=0, std=0.5, seed=None):\n",
    "    \"\"\"\n",
    "    Add Gaussian noise to an image.\n",
    "    \n",
    "    Args:\n",
    "        image (NDarray): the input image in the format cv2 uses\n",
    "        mean (float): the mean of the Gaussian noise\n",
    "        std (float): the standard deviation of the Gaussian noise\n",
    "        seed (int): the seed to be used for the random number generator \n",
    "    \n",
    "    Returns:\n",
    "        NDarray: the image with the added Gaussian noise\n",
    "    \"\"\"\n",
    "    # Sets the seed\n",
    "    numpy.random.seed(seed)\n",
    "\n",
    "    # Generate Gaussian noise\n",
    "    gaussian_noise = numpy.random.normal(mean, std, image.shape).astype('uint8')\n",
    "    \n",
    "    # Add the Gaussian noise to the image\n",
    "    noisy_image = cv2.add(image, gaussian_noise)\n",
    "    \n",
    "    return noisy_image\n",
    "\n",
    "noisy_patch = add_gaussian_noise(numpy.array(patch), seed=SEED)\n",
    "plt.imshow(noisy_patch, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches centered on each pixel\n",
    "\n",
    "def extract_all_centered_patches(image, height, width):\n",
    "    \"\"\"\n",
    "    Extracts a patch centered at each pixel in the image.\n",
    "    \n",
    "    Args:\n",
    "        image (NDarray): Input image as a 2D array.\n",
    "        height (int): Height of the patch.\n",
    "        width (int): Width of the patch.\n",
    "    \n",
    "    Returns:\n",
    "        NDarray[NDarray[NDarray]]: Array containing all the extracted patches\n",
    "    \"\"\"\n",
    "    \n",
    "    H, W = image.shape\n",
    "    \n",
    "    # Calculate half sizes\n",
    "    h_half = height // 2\n",
    "    w_half = width // 2\n",
    "    \n",
    "    # Pad the image to handle border pixels\n",
    "    padded_img = cv2.copyMakeBorder(image, h_half, h_half, w_half, w_half, \n",
    "                                    borderType=cv2.BORDER_REFLECT) \n",
    "    # Border reflect was used due to it seemingly being common practice\n",
    "    \n",
    "    # Initialize an array to hold the patches\n",
    "    patches = numpy.empty((H*W, height, width), dtype=image.dtype)\n",
    "    \n",
    "    # Loop over each pixel position in the original image\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            patch = padded_img[i: i + height, \n",
    "                               j: j + width]\n",
    "            patches[i*W+j] = patch\n",
    "    \n",
    "    return patches\n",
    "\n",
    "\n",
    "extracted_patches=extract_all_centered_patches(noisy_patch, PATCH_SIZE, PATCH_SIZE)\n",
    "print(extracted_patches.shape)\n",
    "plt.imshow(extracted_patches[12345],cmap=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def block_matching_similar_patches(patches, height, width, xi, w):\n",
    "    \"\"\"\n",
    "    Given an array of patches extracted from an image and a threshold xi,\n",
    "    performs block matching within a window of size w x w for each patch.\n",
    "    \n",
    "    Args:\n",
    "        patches (NDarray): Array of extracted patches from extract_all_centered_patches()\n",
    "        height (int): Height of the original image.\n",
    "        width (int): Width of the original image.\n",
    "        xi (float): Threshold for the squared Euclidean distance.\n",
    "        w (int): Size of the search window (w x w).\n",
    "        \n",
    "    Returns:\n",
    "        similar_patches (list): A list containing for every pixel in the original imagean array \n",
    "                                containing the patches similar to the patch centered on that pixel.\n",
    "    \"\"\"\n",
    "    n, _, _ = patches.shape\n",
    "\n",
    "    # initialize list to store the similar patches for each pixel\n",
    "    similar_patches = [None] * n  \n",
    "    \n",
    "    # Pre-compute vectorized patches for fast distance computation\n",
    "    patches_vec = patches.reshape(n, -1)\n",
    "\n",
    "    w_half = w // 2\n",
    "\n",
    "    # Precompute row and col indices\n",
    "    row_indices = numpy.arange(height).repeat(width)\n",
    "    col_indices = numpy.tile(numpy.arange(width), height)\n",
    "\n",
    "    for i in range(n):\n",
    "        row, col = row_indices[i], col_indices[i]\n",
    "\n",
    "        # Define window boundaries\n",
    "        r_min, r_max = max(0, row - w_half), min(height - 1, row + w_half)\n",
    "        c_min, c_max = max(0, col - w_half), min(width - 1, col + w_half)\n",
    "\n",
    "        # Get the indices for patches within the window.\n",
    "        r_grid, c_grid = numpy.meshgrid(numpy.arange(r_min, r_max + 1), \n",
    "                                        numpy.arange(c_min, c_max + 1), indexing='ij')\n",
    "        candidate_indices = (r_grid * width + c_grid).ravel()\n",
    "\n",
    "        # Compute squared Euclidean distances\n",
    "        patch_current = patches_vec[i]\n",
    "        candidates = patches_vec[candidate_indices]\n",
    "        dists = numpy.sum((candidates - patch_current) ** 2, axis=1)\n",
    "\n",
    "        # Filter patches based on threshold\n",
    "        similar_patches[i] = patches[candidate_indices[dists <= xi]]\n",
    "\n",
    "    return similar_patches\n",
    "\n",
    "# xi = (128 ** 2) / (PATCH_SIZE**2)  # TODO tuning\n",
    "# start_time = time.time()\n",
    "# similar_patches = block_matching_similar_patches(extracted_patches, EXAMPLE_SIZE, EXAMPLE_SIZE, xi, 64)\n",
    "# end_time = time.time()\n",
    "# print(f\"Execution Time (xi=128^2): {end_time - start_time:.2f} seconds\")\n",
    "# print(similar_patches[22000].size / PATCH_SIZE**2)\n",
    "\n",
    "# xi = (256 ** 2) / (PATCH_SIZE**2)  # TODO tuning\n",
    "# start_time = time.time()\n",
    "# similar_patches = block_matching_similar_patches(extracted_patches, EXAMPLE_SIZE, EXAMPLE_SIZE, xi, 64)\n",
    "# end_time = time.time()\n",
    "# print(f\"Execution Time (xi=256^2): {end_time - start_time:.2f} seconds\")\n",
    "# print(similar_patches[22000].size / PATCH_SIZE**2)\n",
    "# \n",
    "# xi = (512 ** 2) / (PATCH_SIZE**2)  # TODO tuning\n",
    "# start_time = time.time()\n",
    "# similar_patches = block_matching_similar_patches(extracted_patches, EXAMPLE_SIZE, EXAMPLE_SIZE, xi, 64)\n",
    "# end_time = time.time()\n",
    "# print(f\"Execution Time (xi=512^2): {end_time - start_time:.2f} seconds\")\n",
    "# print(similar_patches[22000].size / PATCH_SIZE**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_patch_batch(start_idx, end_idx, patches, patches_vec, xi, neighbor_indices):\n",
    "    \"\"\"\n",
    "    Process a batch of patches to find similar patches within the search window.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for i in range(start_idx, end_idx):\n",
    "        candidate_indices = neighbor_indices[i]\n",
    "        \n",
    "        # Compute squared Euclidean distances in a vectorized manner\n",
    "        patch_current = patches_vec[i]\n",
    "        candidates = patches_vec[candidate_indices]\n",
    "        dists = numpy.sum((candidates - patch_current) ** 2, axis=1)\n",
    "\n",
    "        # Select patches within the threshold\n",
    "        results[i] = patches[candidate_indices[dists <= xi]]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def precompute_neighbor_indices(height, width, w):\n",
    "    \"\"\"\n",
    "    Precompute the indices of all neighboring patches within the window for each pixel.\n",
    "    \"\"\"\n",
    "    n = height * width\n",
    "    w_half = w // 2\n",
    "    row_indices = numpy.arange(height).repeat(width)\n",
    "    col_indices = numpy.tile(numpy.arange(width), height)\n",
    "    neighbor_indices = []\n",
    "\n",
    "    for i in range(n):\n",
    "        row, col = row_indices[i], col_indices[i]\n",
    "\n",
    "        # Define window boundaries\n",
    "        r_min, r_max = max(0, row - w_half), min(height - 1, row + w_half)\n",
    "        c_min, c_max = max(0, col - w_half), min(width - 1, col + w_half)\n",
    "\n",
    "        # Generate candidate indices within the window\n",
    "        r_grid, c_grid = numpy.meshgrid(numpy.arange(r_min, r_max + 1), numpy.arange(c_min, c_max + 1),\n",
    "                                         indexing='ij')\n",
    "        neighbor_indices.append((r_grid * width + c_grid).ravel())\n",
    "\n",
    "    return numpy.array(neighbor_indices, dtype=object)\n",
    "\n",
    "\n",
    "def block_matching_similar_patches_concurrent(patches, height, width, xi, w, num_workers=12):\n",
    "    \"\"\"\n",
    "    Given an array of patches extracted from an image and a threshold xi,\n",
    "    performs block matching within a window of size w x w for each patch.\n",
    "    \n",
    "    Args:\n",
    "        patches (NDarray): Array of extracted patches from extract_all_centered_patches()\n",
    "        height (int): Height of the original image.\n",
    "        width (int): Width of the original image.\n",
    "        xi (float): Threshold for the squared Euclidean distance.\n",
    "        w (int): Size of the search window (w x w).\n",
    "        num_workers (int): number of threads you want to use\n",
    "        \n",
    "    Returns:\n",
    "        similar_patches (list): A list containing for every pixel in the original imagean array \n",
    "                                containing the patches similar to the patch centered on that pixel.\n",
    "    \"\"\"\n",
    "    n, _, _ = patches.shape\n",
    "    patches_vec = patches.reshape(n, -1)\n",
    "\n",
    "    # Precompute neighbor indices for all patches\n",
    "    neighbor_indices = precompute_neighbor_indices(height, width, w)\n",
    "\n",
    "    # Initialize list to store results\n",
    "    similar_patches = [None] * n\n",
    "\n",
    "    # Divide patches into chunks\n",
    "    chunk_size = max(1, n // num_workers)\n",
    "    chunks = [(i, min(i + chunk_size, n)) for i in range(0, n, chunk_size)]\n",
    "\n",
    "    # Use ThreadPoolExecutor to process batches in parallel\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(process_patch_batch, start, end, patches, patches_vec, \n",
    "                            xi, neighbor_indices): (start, end)\n",
    "            for start, end in chunks\n",
    "        }\n",
    "\n",
    "        # Collect results\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            batch_results = future.result()\n",
    "            for i, result in batch_results.items():\n",
    "                similar_patches[i] = result\n",
    "\n",
    "    return similar_patches\n",
    "\n",
    "xi = (128 ** 2) / (PATCH_SIZE**2)  # TODO tuning\n",
    "start_time = time.time()\n",
    "similar_patches = block_matching_similar_patches_concurrent(extracted_patches, EXAMPLE_SIZE, EXAMPLE_SIZE, xi, 64)\n",
    "end_time = time.time()\n",
    "print(f\"Execution Time (xi=128^2): {end_time - start_time:.2f} seconds\")\n",
    "print(similar_patches[22000].size / PATCH_SIZE**2)\n",
    "\n",
    "# xi = (256 ** 2) / (PATCH_SIZE**2)  # TODO tuning\n",
    "# start_time = time.time()\n",
    "# similar_patches = block_matching_similar_patches_concurrent(extracted_patches, EXAMPLE_SIZE, EXAMPLE_SIZE, xi, 64)\n",
    "# end_time = time.time()\n",
    "# print(f\"Execution Time (xi=256^2): {end_time - start_time:.2f} seconds\")\n",
    "# print(similar_patches[22000].size / PATCH_SIZE**2)\n",
    "\n",
    "# xi = (512 ** 2) / (PATCH_SIZE**2)  # TODO tuning\n",
    "# start_time = time.time()\n",
    "# similar_patches = block_matching_similar_patches_concurrent(extracted_patches, EXAMPLE_SIZE, EXAMPLE_SIZE, xi, 64)\n",
    "# end_time = time.time()\n",
    "# print(f\"Execution Time (xi=512^2): {end_time - start_time:.2f} seconds\")\n",
    "# print(similar_patches[22000].size / PATCH_SIZE**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of right now, this is what we have:\n",
    "- `noisy_image`: the image on which we are learning the A coefficients as a numpy array\n",
    "- `extracted_patches`: list of all patches\n",
    "- `similar_patches`: list that, for each pixels, contains a numpy array of patches, each one being a numpy matrix of size PxP\n",
    "- `model`: initial learned dictionary on a training dataset, of which `model.components_` has the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extracted_patches.shape)\n",
    "print(len(similar_patches))\n",
    "print(model.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import MultiTaskLasso\n",
    "\n",
    "def optimize_equation_8(Y, D, S, p=1, q=2, epsilon=None):\n",
    "    \"\"\"\n",
    "    Solves the optimization problem in Equation (8) for non-local sparse coding.\n",
    "\n",
    "    Parameters:\n",
    "    - Y: np.ndarray of shape (l, P, P), image patches for each pixel.\n",
    "    - D: sklearn MiniBatchDictionaryLearning object or np.ndarray of shape (k, P*P), dictionary components.\n",
    "    - S: list of np.ndarrays, where each entry contains a set of similar patches of shape (N, P, P).\n",
    "    - p, q: Norm parameters, default to (1,2) for the convex case.\n",
    "    - epsilon: np.ndarray of shape (l,) or None, error tolerance for each patch group.\n",
    "\n",
    "    Returns:\n",
    "    - A: np.ndarray of shape (k, l), the sparse coefficient matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    l, P, _ = Y.shape  # Number of pixels and patch size\n",
    "    k = D.components_.shape[0] if hasattr(D, \"components_\") else D.shape[0]  # Dictionary size\n",
    "    D_matrix = D.components_ if hasattr(D, \"components_\") else D  # Extract dictionary components\n",
    "    D_matrix = D_matrix.reshape(k, P * P)  # Ensure dictionary is in matrix form\n",
    "\n",
    "    A = np.zeros((k, l))  # Initialize sparse coefficient matrix\n",
    "\n",
    "    for i in range(l):\n",
    "        print(\"i:\", i)\n",
    "        Si = S[i]  # Get similar patches as a numpy array of shape (N, P, P)\n",
    "        if Si.shape[0] == 0:\n",
    "            continue  # Skip if no similar patches\n",
    "\n",
    "        Y_Si = Si.reshape(Si.shape[0], P * P)  # Flatten patches to (N, P*P)\n",
    "        epsilon_i = epsilon[i] if epsilon is not None else 1e-3  # Default tolerance\n",
    "\n",
    "        # Solve the sparse coding problem with joint sparsity\n",
    "        A[:, i] = solve_sparse_group_lasso(Y_Si, D_matrix, p, q, epsilon_i)\n",
    "\n",
    "    return A\n",
    "\n",
    "\n",
    "def solve_sparse_group_lasso(Y_Si, D_matrix, p, q, epsilon):\n",
    "    \"\"\"\n",
    "    Solves the group sparse coding problem for a set of similar patches.\n",
    "\n",
    "    Parameters:\n",
    "    - Y_Si: np.ndarray of shape (N, P*P), flattened patches in the similarity group.\n",
    "    - D_matrix: np.ndarray of shape (k, P*P), dictionary elements.\n",
    "    - p, q: Norm parameters, default (1,2) for convex formulation.\n",
    "    - epsilon: Error tolerance for the constraint.\n",
    "\n",
    "    Returns:\n",
    "    - A_Si: np.ndarray of shape (k,), the sparse coefficient vector for the pixel.\n",
    "    \"\"\"\n",
    "    if Y_Si.shape[0] == 0:\n",
    "        return np.zeros(D_matrix.shape[0])  # Return zero vector if no patches\n",
    "\n",
    "    # Solve sparse coding using MultiTaskLasso (convex case)\n",
    "    lasso = MultiTaskLasso(alpha=epsilon, fit_intercept=False)\n",
    "    A_Si = lasso.fit(D_matrix.T, Y_Si.T).coef_.T  # Fix the inconsistent dimensions\n",
    "\n",
    "    return A_Si.mean(axis=1)  # Average over similar patches\n",
    "\n",
    "def optimize_equation_8_batch(Y, D, S, epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Optimized batch version of Equation (8).\n",
    "\n",
    "    Parameters:\n",
    "    - Y: np.ndarray of shape (l, P, P), image patches.\n",
    "    - D: np.ndarray of shape (k, P*P), dictionary.\n",
    "    - S: list of np.ndarray, similar patches.\n",
    "    - epsilon: float, error tolerance.\n",
    "\n",
    "    Returns:\n",
    "    - A: np.ndarray of shape (k, l), the sparse coefficient matrix.\n",
    "    \"\"\"\n",
    "    l, P, _ = Y.shape\n",
    "    k = D.shape[0]\n",
    "    D_matrix = D.reshape(k, P * P)\n",
    "\n",
    "    # Flatten patches\n",
    "    Y_flat = Y.reshape(l, P * P)\n",
    "\n",
    "    # Use batch sparse coding solver (e.g., LassoLars)\n",
    "    from sklearn.linear_model import LassoLars\n",
    "    lasso = LassoLars(alpha=epsilon)\n",
    "\n",
    "    A = np.zeros((k, l))\n",
    "    A = lasso.fit(D_matrix.T, Y_flat.T).coef_.T  # Solve in batch\n",
    "\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def soft_thresholding(x, threshold):\n",
    "    \"\"\"Applies soft-thresholding element-wise.\"\"\"\n",
    "    return np.sign(x) * np.maximum(np.abs(x) - threshold, 0)\n",
    "\n",
    "def ista(Y, D, lambda_, L, num_iters=50):\n",
    "    \"\"\"\n",
    "    Solves min_A Y - DA^2_F + lambda ||A||_1 using ISTA.\n",
    "\n",
    "    Parameters:\n",
    "    - Y: (P^2 x l) Matrix of vectorized similar patches.\n",
    "    - D: (P^2 x k) Dictionary.\n",
    "    - lambda_: Regularization parameter for sparsity.\n",
    "    - L: Step size (largest eigenvalue of D^T D).\n",
    "    - num_iters: Number of ISTA iterations.\n",
    "\n",
    "    Returns:\n",
    "    - A: (k x l) Sparse coefficients for the group.\n",
    "    \"\"\"\n",
    "    k, l = D.shape[1], Y.shape[1]  # Number of dictionary atoms and patches\n",
    "    A = np.zeros((k, l))  # Initialize sparse codes\n",
    "\n",
    "    DtD = D.T @ D  # Precompute D^T D\n",
    "    DtY = D.T @ Y  # Precompute D^T Y\n",
    "    step_size = 1.0 / L\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        A = soft_thresholding(A - step_size * (DtD @ A - DtY), lambda_ * step_size)\n",
    "\n",
    "    return A\n",
    "\n",
    "def solve_nonlocal_sparse_coding(similar_patches, model, lambda_=0.1, num_iters=50):\n",
    "    \"\"\"\n",
    "    Solves equation (8) using ISTA for simultaneous sparse coding.\n",
    "\n",
    "    Parameters:\n",
    "    - similar_patches: List where each entry contains similar patches.\n",
    "    - model: Pre-trained dictionary (model.components_).\n",
    "    - lambda_: Sparsity regularization parameter.\n",
    "    - num_iters: Number of ISTA iterations.\n",
    "\n",
    "    Returns:\n",
    "    - A: Dictionary mapping each pixel index to its sparse code matrix.\n",
    "    - D: Dictionary used for reconstruction.\n",
    "    \"\"\"\n",
    "    D = model.components_.T  # Dictionary shape (P^2, k)\n",
    "    restored_coeffs = {}\n",
    "\n",
    "    for i, patch_group in enumerate(similar_patches):\n",
    "        if len(patch_group) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Stack similar patches into matrix Y (each column is a vectorized patch)\n",
    "        Y = np.array(patch_group).reshape(len(patch_group), -1).T  # (P^2, l)\n",
    "        L = np.linalg.norm(D.T @ D, 2)  # Step size (largest eigenvalue)\n",
    "\n",
    "        # Compute sparse codes for group using ISTA\n",
    "        A_i = ista(Y, D, lambda_, L, num_iters)\n",
    "        restored_coeffs[i] = A_i  # Store coefficients\n",
    "\n",
    "    return restored_coeffs # Return learned coefficients and dictionary\n",
    "\n",
    "B=solve_nonlocal_sparse_coding(extracted_patches, similar_patches, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = optimize_equation_8_batch(extracted_patches, model.components_, similar_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reconstruct_image(A, D, S, image_shape, P):\n",
    "    \"\"\"\n",
    "    Reconstructs the original image using Equation (9) from the paper.\n",
    "\n",
    "    Parameters:\n",
    "    - A: np.ndarray of shape (k, l), the sparse coefficient matrix.\n",
    "    - D: np.ndarray of shape (k, P*P), the learned dictionary.\n",
    "    - S: list of np.ndarrays, each containing similar patches for a given pixel.\n",
    "    - image_shape: tuple (H, W), the height and width of the original image.\n",
    "    - P: int, the side length of each patch.\n",
    "\n",
    "    Returns:\n",
    "    - x: np.ndarray of shape (H, W), the reconstructed image.\n",
    "    \"\"\"\n",
    "    H, W = image_shape\n",
    "    l = len(S)  # Number of pixels in the image\n",
    "    x = np.zeros((H, W))  # Initialize the reconstructed image\n",
    "    weight = np.zeros((H, W))  # Normalization matrix to account for overlapping patches\n",
    "\n",
    "    half_P = P // 2  # Half patch size for placement\n",
    "\n",
    "    for i in range(l):\n",
    "        Si = S[i]  # Set of similar patches (N, P, P)\n",
    "        if Si.shape[0] == 0:\n",
    "            continue  # Skip if no similar patches\n",
    "        \n",
    "        # Compute the reconstructed patch from sparse coefficients\n",
    "        reconstructed_patches = (D.T @ A[:, i]).reshape(P, P)  # Reshape to (P, P)\n",
    "\n",
    "        # Find pixel location in the original image\n",
    "        row = i // W  # Row index of the pixel\n",
    "        col = i % W   # Column index of the pixel\n",
    "\n",
    "        # Compute valid patch region within the image bounds\n",
    "        row_start, row_end = max(row - half_P, 0), min(row - half_P + P, H)\n",
    "        col_start, col_end = max(col - half_P, 0), min(col - half_P + P, W)\n",
    "\n",
    "        # Crop the patch to fit inside the image if needed\n",
    "        patch_r_start = max(half_P - row, 0)\n",
    "        patch_r_end = patch_r_start + (row_end - row_start)\n",
    "        patch_c_start = max(half_P - col, 0)\n",
    "        patch_c_end = patch_c_start + (col_end - col_start)\n",
    "\n",
    "        x[row_start:row_end, col_start:col_end] += reconstructed_patches[patch_r_start:patch_r_end, patch_c_start:patch_c_end]\n",
    "        weight[row_start:row_end, col_start:col_end] += 1  # Keep track of how many patches contribute to each pixel\n",
    "\n",
    "    # Normalize by the number of overlapping patches\n",
    "    weight[weight == 0] = 1  # Avoid division by zero\n",
    "    x /= weight  # Normalize pixel values\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = reconstruct_image(A, model.components_, similar_patches, (noisy_patch.shape[0], noisy_patch.shape[1]), 8)\n",
    "\n",
    "# Normalize the reconstructed image (if needed)\n",
    "reconstructed_display = reconstructed - reconstructed.min()  # Shift values to start from 0\n",
    "reconstructed_display /= reconstructed_display.max()  # Scale to [0, 1]\n",
    "\n",
    "# Show image with grayscale colormap\n",
    "plt.imshow(reconstructed_display, cmap=\"gray\")\n",
    "plt.axis(\"off\")  # Hide axes for better visualization™i\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def display_patch_sets(similar_patches,pixel_index, height, width, cmap='gray'):\n",
    "    \"\"\"\n",
    "    Display all patches from one similar patch sets.\n",
    "    \n",
    "    Args:\n",
    "        similar_patches (list or dict): The output from block_matching_similar_patches.\n",
    "        pixel_index (int): Index of patch set you want to display.\n",
    "        height (int): The patch height, must be positive.\n",
    "        width (int): The patch width, must be positive.\n",
    "        cmap (str): Color map to use for display, default is 'gray'.\n",
    "    \"\"\"\n",
    "     \n",
    "    # Prepare the patches\n",
    "    patches = similar_patches[pixel_index]\n",
    "    num_patches = patches.shape[0]\n",
    "    # Determine grid size for the set\n",
    "    cols = min(10, num_patches)\n",
    "    rows = math.ceil(num_patches / cols)\n",
    "    # Prepare the figure\n",
    "    plt.figure(figsize=(cols * 1.5, rows * 1.5))\n",
    "    plt.suptitle(f\"Similar patches for pixel index {pixel_index}\", fontsize=16)\n",
    "    \n",
    "    # Display one by one the patches\n",
    "    for i in range(num_patches):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        patch = patches[i].reshape(height, width)\n",
    "        plt.imshow(patch, cmap=cmap,vmin=0,vmax=255)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "display_patch_sets(similar_patches, 22000, PATCH_SIZE, PATCH_SIZE)\n",
    "print(similar_patches[22000][0]-similar_patches[22000][1])\n",
    "plt.imshow(similar_patches[22000][1],cmap=\"grey\",vmin=0,vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_reconstructed = reconstruct_image(B, model.components_, similar_patches, (noisy_patch.shape[0], noisy_patch.shape[1]), 8)\n",
    "\n",
    "# Normalize the reconstructed image (if needed)\n",
    "reconstructed_display = reconstructed - reconstructed.min()  # Shift values to start from 0\n",
    "reconstructed_display /= reconstructed_display.max()  # Scale to [0, 1]\n",
    "\n",
    "# Show image with grayscale colormap\n",
    "plt.imshow(reconstructed_display, cmap=\"gray\")\n",
    "plt.axis(\"off\")  # Hide axes for better visualization™i\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
